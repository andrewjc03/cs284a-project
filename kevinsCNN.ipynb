{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6771911c-02a5-459d-bc2e-b632797555ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cb036b1-08a0-4531-8c4f-27c4c0d5d8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_code  diagnosis\n",
      "0  000c1434d8d7          2\n",
      "1  001639a390f0          4\n",
      "2  0024cdab0c1e          1\n",
      "3  002c21358ce6          0\n",
      "4  005b95c28852          0\n",
      "        id_code\n",
      "0  0005cfc8afb6\n",
      "1  003f0afdcd15\n",
      "2  006efc72b638\n",
      "3  00836aaacf06\n",
      "4  009245722fa4\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"C:/Users/15105/Downloads/aptos2019-blindness-detection\"\n",
    "\n",
    "train_csv_path = os.path.join(DATA_DIR, \"train.csv\")\n",
    "test_csv_path = os.path.join(DATA_DIR, \"test.csv\")\n",
    "train_img_dir = os.path.join(DATA_DIR, \"train_images\")\n",
    "test_img_dir = os.path.join(DATA_DIR, \"test_images\")\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3837033e-5fda-40b5-8861-1e5a0a09d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, has_labels=True):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.has_labels = has_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # ALWAYS add the extension\n",
    "        img_name = row[\"id_code\"] + \".png\"\n",
    "        image_path = os.path.join(self.img_dir, img_name)\n",
    "\n",
    "        # Debug if file missing\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "        # Open image\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.has_labels:\n",
    "            label = int(row[\"diagnosis\"])\n",
    "            return img, img_name, label\n",
    "\n",
    "        return img, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29792427-e147-4fb3-826d-e7cec739fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a3c6252-5c6d-4865-a534-73b90945436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "train_dataset = RetinopathyDataset(\n",
    "    df=train_df,\n",
    "    img_dir=train_img_dir,\n",
    "    transform=train_transforms,\n",
    "    has_labels=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# TEST (no labels)\n",
    "test_dataset = RetinopathyDataset(\n",
    "    df=test_df,\n",
    "    img_dir=test_img_dir,\n",
    "    transform=test_transforms,\n",
    "    has_labels=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d4d78aa-b86d-442b-913f-5525145b2ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDRCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(SimpleDRCNN, self).__init__()\n",
    "        \n",
    "        # Conv layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # -> 32 x 128 x 128\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # -> 64 x 64 x 64\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # -> 128 x 32 x 32\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Compute flattened feature size: 128 channels, 32x32 after pooling\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)  # -> 32 x 64 x 64\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)  # -> 64 x 32 x 32\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)  # -> 128 x 16 x 16\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4bb1f2d-5c97-492c-9e09-86eda41f2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = SimpleDRCNN(num_classes=5).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86a3bc6a-3bd3-4906-b65a-04ed4a0ecbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Epoch [1/3], Step [10/58], Loss: 1.0090\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Epoch [1/3], Step [20/58], Loss: 0.8146\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "Epoch [1/3], Step [30/58], Loss: 0.7759\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "Epoch [1/3], Step [40/58], Loss: 0.7499\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Epoch [1/3], Step [50/58], Loss: 1.0296\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Epoch [2/3], Step [10/58], Loss: 0.6152\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Epoch [2/3], Step [20/58], Loss: 0.9305\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "Epoch [2/3], Step [30/58], Loss: 0.7312\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "Epoch [2/3], Step [40/58], Loss: 0.7935\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Epoch [2/3], Step [50/58], Loss: 0.7265\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Epoch [3/3], Step [10/58], Loss: 0.6292\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Epoch [3/3], Step [20/58], Loss: 0.6239\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "Epoch [3/3], Step [30/58], Loss: 0.7629\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "Epoch [3/3], Step [40/58], Loss: 0.8084\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Epoch [3/3], Step [50/58], Loss: 0.9564\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for i, (imgs, _, labels) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(i)\n",
    "        if (i+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95cd4de-c77b-414e-b7da-0920ef5b2b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a04f9c-f774-4112-bc69-3efaae067ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
