{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Getting Started with Machine Learning for Image Datasets\n", "This notebook walks you through loading an image dataset, preprocessing images, building a simple CNN, training, and evaluating."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import tensorflow as tf\n", "import matplotlib.pyplot as plt\n", "from tensorflow.keras import layers, models\n", "\n", "print('TensorFlow version:', tf.__version__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Image Dataset\n", "Using TensorFlow's `image_dataset_from_directory`."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["data_dir = 'path/to/images'  # replace with your dataset directory\n", "img_size = (224, 224)\n", "batch_size = 32\n", "\n", "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n", "    data_dir,\n", "    validation_split=0.2,\n", "    subset=\"training\",\n", "    seed=42,\n", "    image_size=img_size,\n", "    batch_size=batch_size\n", ")\n", "\n", "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n", "    data_dir,\n", "    validation_split=0.2,\n", "    subset=\"validation\",\n", "    seed=42,\n", "    image_size=img_size,\n", "    batch_size=batch_size\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preprocessing and Caching"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["AUTOTUNE = tf.data.AUTOTUNE\n", "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n", "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Build a Simple CNN Model"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["model = models.Sequential([\n", "    layers.Rescaling(1./255, input_shape=img_size + (3,)),\n", "    layers.Conv2D(32, (3,3), activation='relu'),\n", "    layers.MaxPooling2D(),\n", "    layers.Conv2D(64, (3,3), activation='relu'),\n", "    layers.MaxPooling2D(),\n", "    layers.Flatten(),\n", "    layers.Dense(128, activation='relu'),\n", "    layers.Dense(10)  # adjust depending on number of classes\n", "])\n", "\n", "model.compile(\n", "    optimizer='adam',\n", "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n", "    metrics=['accuracy']\n", ")\n", "\n", "model.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train the Model"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["history = model.fit(train_ds, validation_data=val_ds, epochs=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Plot Results"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["acc = history.history['accuracy']\n", "val_acc = history.history['val_accuracy']\n", "plt.plot(acc)\n", "plt.plot(val_acc)\n", "plt.title('Training and Validation Accuracy')\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}